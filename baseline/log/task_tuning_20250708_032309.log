2025-07-08 03:23:13,957 INFO Logger initialized
2025-07-08 03:23:13,957 INFO Config path: config_task_tuning.yml
2025-07-08 03:23:13,957 INFO Config file contents:
test_type: "task_tuning"
model_module: "SpectralGPT" # or "SoftCon"

params:
  countries: ["Finland", "Ireland", "Serbia", "Portugal"]
  permutation: [0, 1, 2, 3]  # indices for the countries
  train_samples: 5000  # samples per country for training
  test_samples: 500    # samples per country for testing
  seed: 42
  batch_size: 16
  num_workers: 4
  epoch: 20
  lr: 1e-4
  r: 4
  include_snowy: false
  include_cloudy: false

  save_dir: /faststorage/continual_low_rank_adaptation_of_remote_sensing_foundation_models/SpectralGPT/saved_models/epoch15                # Verzeichnis zum Speichern der Modelle
  log_every_step: true

2025-07-08 03:23:13,960 INFO Using model module: SpectralGPT
/faststorage/arne/mamba/envs/cl_lora_env/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-07-08 03:23:14,096 INFO Save directory set to: /faststorage/continual_low_rank_adaptation_of_remote_sensing_foundation_models/SpectralGPT/saved_models/epoch15/task_tuning/permutation_0_1_2_3
img_size (128, 128) patch_size (8, 8) frames 12 t_patch_size 3
Embedding size of ckpt: 768
Number of patches of model: 1024
Number of extra tokens of model: -768
Original size of ckpt: 12
New size of model: 16
Position interpolate from 12x12 to 16x16
Loaded with: <All keys matched successfully>
ViT trainable parameters w/o LoRA: 85403904
LoRA_SViT(
  (lora_vit): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(1, 768, kernel_size=(3, 8, 8), stride=(3, 8, 8))
    )
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.018)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.036)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.055)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.091)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.109)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.127)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.145)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.164)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.182)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (k): Linear(in_features=768, out_features=768, bias=True)
          (v): _LoRALayer(
            (w): Linear(in_features=768, out_features=768, bias=True)
            (w_a): Linear(in_features=768, out_features=4, bias=False)
            (w_b): Linear(in_features=4, out_features=768, bias=False)
          )
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.200)
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (dropout): Dropout(p=0, inplace=False)
    (fc): Linear(in_features=768, out_features=19, bias=True)
  )
2025-07-08 03:24:14,292 INFO Task 1: Training independently on Finland
)

Number of trainable parameters: (w/ LoRA) 162067
[96m[INFO]    Loading BEN data for train...[0m
[96m[INFO]        237871 patches indexed[0m
[96m[INFO]        4000 pre-filtered patches indexed[0m
[96m[INFO]        4000 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for train...[0m
[96m[INFO]        237871 patches indexed[0m
[96m[INFO]        1000 pre-filtered patches indexed[0m
[96m[INFO]        1000 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for train...[0m
[96m[INFO]        237871 patches indexed[0m
[96m[INFO]        4000 pre-filtered patches indexed[0m
[96m[INFO]        4000 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for train...[0m
[96m[INFO]        237871 patches indexed[0m
[96m[INFO]        1000 pre-filtered patches indexed[0m
[96m[INFO]        1000 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for train...[0m
[96m[INFO]        237871 patches indexed[0m
[96m[INFO]        4000 pre-filtered patches indexed[0m
[96m[INFO]        4000 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for train...[0m
[96m[INFO]        237871 patches indexed[0m
[96m[INFO]        1000 pre-filtered patches indexed[0m
[96m[INFO]        1000 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for train...[0m
[96m[INFO]        237871 patches indexed[0m
[96m[INFO]        4000 pre-filtered patches indexed[0m
[96m[INFO]        4000 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for train...[0m
[96m[INFO]        237871 patches indexed[0m
[96m[INFO]        1000 pre-filtered patches indexed[0m
[96m[INFO]        1000 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for test...[0m
[96m[INFO]        119825 patches indexed[0m
[96m[INFO]        500 pre-filtered patches indexed[0m
[96m[INFO]        500 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for test...[0m
[96m[INFO]        119825 patches indexed[0m
[96m[INFO]        0 pre-filtered patches indexed[0m
[96m[INFO]        0 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for test...[0m
[96m[INFO]        119825 patches indexed[0m
[96m[INFO]        500 pre-filtered patches indexed[0m
[96m[INFO]        500 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for test...[0m
[96m[INFO]        119825 patches indexed[0m
[96m[INFO]        0 pre-filtered patches indexed[0m
[96m[INFO]        0 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for test...[0m
[96m[INFO]        119825 patches indexed[0m
[96m[INFO]        500 pre-filtered patches indexed[0m
[96m[INFO]        500 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for test...[0m
[96m[INFO]        119825 patches indexed[0m
[96m[INFO]        0 pre-filtered patches indexed[0m
[96m[INFO]        0 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for test...[0m
[96m[INFO]        119825 patches indexed[0m
[96m[INFO]        500 pre-filtered patches indexed[0m
[96m[INFO]        500 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
[96m[INFO]    Loading BEN data for test...[0m
[96m[INFO]        119825 patches indexed[0m
[96m[INFO]        0 pre-filtered patches indexed[0m
[96m[INFO]        0 filtered patches indexed[0m
[96m[INFO]    Merged metadata with snow/cloud metadata[0m
[96m[INFO]    Loaded 549488 labels[0m
[96m[INFO]    Loaded 549488 keys[0m
[96m[INFO]    Loaded mapping created[0m
Traceback (most recent call last):
  File "/home/arne/src/baseline/baseline.py", line 754, in <module>
    main()
  File "/home/arne/src/baseline/baseline.py", line 750, in main
    print(main_from_config(args.config))
  File "/home/arne/src/baseline/baseline.py", line 726, in main_from_config
    return test_task_tuning(model, params)
  File "/home/arne/src/baseline/baseline.py", line 580, in test_task_tuning
    base_model = load_model(r=rank)
NameError: name 'rank' is not defined
srun: error: erde: task 0: Exited with exit code 1
