# Konfigurationsdatei für Continual-Learning-Merging

# Test-Typ: ZipLoRA , LoRASoups or LoRAHub
test_type: LoRASoups

# Modell-Definition
model_module: SpectralGPT  # Options: 'SpectralGPT' or 'SoftCon'

# Parameter für die Tests
params:
  countries:
    - Finland
    - Ireland
    - Serbia
    - Portugal
  permutation: [0, 1, 2, 3]                # Reihenfolge der Länder-Indices

  # Subset fraction for stratified sampling (5-10% as mentioned in merge.py)
  subset_fraction: 0.1                         # Required by merge.py for creating subsets

  # Anzahl der zufällig gezogenen Samples pro Land
  train_samples: 5 #22482
  test_samples: 1 #8176
  seed: 42                              # Seed für Reproduzierbarkeit

  # DataLoader-Parameter
  batch_size: 16                        # Reduced for testing with small samples
  num_workers: 4
  epoch: 1
  lr: 1e-4                              # Changed to match merge.py default (1e-4, not 1e-3)

  # Bildgröße und Filteroptionen
  include_snowy: false
  include_cloudy: false

  save_dir: ./saved_models                # Verzeichnis zum Speichern der Modelle
  weight_base_path: "/faststorage/continual_low_rank_adaptation_of_remote_sensing_foundation_models/SpectralGPT/task_tuning/saved_models"

